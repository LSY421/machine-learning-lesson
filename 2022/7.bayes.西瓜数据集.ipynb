{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['BernoulliNB', 'GaussianNB', 'MultinomialNB', 'ComplementNB', 'CategoricalNB']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import naive_bayes\n",
    "naive_bayes.__all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "    色泽  根蒂  敲声  纹理  脐部  触感     密度    含糖率 好瓜\n编号                                         \n1   青绿  蜷缩  浊响  清晰  凹陷  硬滑  0.697  0.460  是\n2   乌黑  蜷缩  沉闷  清晰  凹陷  硬滑  0.774  0.376  是\n3   乌黑  蜷缩  浊响  清晰  凹陷  硬滑  0.634  0.264  是\n4   青绿  蜷缩  沉闷  清晰  凹陷  硬滑  0.608  0.318  是\n5   浅白  蜷缩  浊响  清晰  凹陷  硬滑  0.556  0.215  是\n6   青绿  稍蜷  浊响  清晰  稍凹  软粘  0.403  0.237  是\n7   乌黑  稍蜷  浊响  稍糊  稍凹  软粘  0.481  0.149  是\n8   乌黑  稍蜷  浊响  清晰  稍凹  硬滑  0.437  0.211  是\n9   乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑  0.666  0.091  否\n10  青绿  硬挺  清脆  清晰  平坦  软粘  0.243  0.267  否\n11  浅白  硬挺  清脆  模糊  平坦  硬滑  0.245  0.057  否\n12  浅白  蜷缩  浊响  模糊  平坦  软粘  0.343  0.099  否\n13  青绿  稍蜷  浊响  稍糊  凹陷  硬滑  0.639  0.161  否\n14  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑  0.657  0.198  否\n15  乌黑  稍蜷  浊响  清晰  稍凹  软粘  0.360  0.370  否\n16  浅白  蜷缩  浊响  模糊  平坦  硬滑  0.593  0.042  否\n17  青绿  蜷缩  沉闷  稍糊  稍凹  硬滑  0.719  0.103  否",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>色泽</th>\n      <th>根蒂</th>\n      <th>敲声</th>\n      <th>纹理</th>\n      <th>脐部</th>\n      <th>触感</th>\n      <th>密度</th>\n      <th>含糖率</th>\n      <th>好瓜</th>\n    </tr>\n    <tr>\n      <th>编号</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.697</td>\n      <td>0.460</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>乌黑</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.774</td>\n      <td>0.376</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>乌黑</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.634</td>\n      <td>0.264</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.608</td>\n      <td>0.318</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.556</td>\n      <td>0.215</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>青绿</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>0.403</td>\n      <td>0.237</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>0.481</td>\n      <td>0.149</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>0.437</td>\n      <td>0.211</td>\n      <td>是</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>0.666</td>\n      <td>0.091</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>青绿</td>\n      <td>硬挺</td>\n      <td>清脆</td>\n      <td>清晰</td>\n      <td>平坦</td>\n      <td>软粘</td>\n      <td>0.243</td>\n      <td>0.267</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>浅白</td>\n      <td>硬挺</td>\n      <td>清脆</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>硬滑</td>\n      <td>0.245</td>\n      <td>0.057</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>软粘</td>\n      <td>0.343</td>\n      <td>0.099</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>青绿</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>稍糊</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.639</td>\n      <td>0.161</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>浅白</td>\n      <td>稍蜷</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>凹陷</td>\n      <td>硬滑</td>\n      <td>0.657</td>\n      <td>0.198</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>乌黑</td>\n      <td>稍蜷</td>\n      <td>浊响</td>\n      <td>清晰</td>\n      <td>稍凹</td>\n      <td>软粘</td>\n      <td>0.360</td>\n      <td>0.370</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>浅白</td>\n      <td>蜷缩</td>\n      <td>浊响</td>\n      <td>模糊</td>\n      <td>平坦</td>\n      <td>硬滑</td>\n      <td>0.593</td>\n      <td>0.042</td>\n      <td>否</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>青绿</td>\n      <td>蜷缩</td>\n      <td>沉闷</td>\n      <td>稍糊</td>\n      <td>稍凹</td>\n      <td>硬滑</td>\n      <td>0.719</td>\n      <td>0.103</td>\n      <td>否</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xigua = pd.read_csv(\"../data/xigua3.0.csv\", index_col='编号')\n",
    "xigua"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "        0      1    2    3    4    5    6    7    8\n1   0.697  0.460  2.0  2.0  1.0  1.0  0.0  0.0  1.0\n2   0.774  0.376  0.0  2.0  0.0  1.0  0.0  0.0  1.0\n3   0.634  0.264  0.0  2.0  1.0  1.0  0.0  0.0  1.0\n4   0.608  0.318  2.0  2.0  0.0  1.0  0.0  0.0  1.0\n5   0.556  0.215  1.0  2.0  1.0  1.0  0.0  0.0  1.0\n6   0.403  0.237  2.0  1.0  1.0  1.0  2.0  1.0  1.0\n7   0.481  0.149  0.0  1.0  1.0  2.0  2.0  1.0  1.0\n8   0.437  0.211  0.0  1.0  1.0  1.0  2.0  0.0  1.0\n9   0.666  0.091  0.0  1.0  0.0  2.0  2.0  0.0  0.0\n10  0.243  0.267  2.0  0.0  2.0  1.0  1.0  1.0  0.0\n11  0.245  0.057  1.0  0.0  2.0  0.0  1.0  0.0  0.0\n12  0.343  0.099  1.0  2.0  1.0  0.0  1.0  1.0  0.0\n13  0.639  0.161  2.0  1.0  1.0  2.0  0.0  0.0  0.0\n14  0.657  0.198  1.0  1.0  0.0  2.0  0.0  0.0  0.0\n15  0.360  0.370  0.0  1.0  1.0  1.0  2.0  1.0  0.0\n16  0.593  0.042  1.0  2.0  1.0  0.0  1.0  0.0  0.0\n17  0.719  0.103  2.0  2.0  0.0  2.0  2.0  0.0  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.697</td>\n      <td>0.460</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.774</td>\n      <td>0.376</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.634</td>\n      <td>0.264</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.608</td>\n      <td>0.318</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.556</td>\n      <td>0.215</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.403</td>\n      <td>0.237</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.481</td>\n      <td>0.149</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.437</td>\n      <td>0.211</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.666</td>\n      <td>0.091</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.243</td>\n      <td>0.267</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.245</td>\n      <td>0.057</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.343</td>\n      <td>0.099</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.639</td>\n      <td>0.161</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.657</td>\n      <td>0.198</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.360</td>\n      <td>0.370</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.593</td>\n      <td>0.042</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.719</td>\n      <td>0.103</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xigua_ls = xigua[['色泽', '根蒂', '敲声', '纹理', '脐部', '触感','好瓜']]\n",
    "xigua_lx = xigua[['密度','含糖率']]\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "xigua_ls_enc = encoder.fit_transform(xigua_ls)\n",
    "xigua_ls_enc_2 = pd.DataFrame(xigua_ls_enc)\n",
    "xigua_ls_enc_2.index += 1\n",
    "\n",
    "xigua_1 = pd.concat([xigua_lx, xigua_ls_enc_2], axis=1)\n",
    "xigua_1.columns = range(len(xigua_1.columns))\n",
    "xigua_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "编号\n1     1\n2     1\n3     1\n4     1\n5     1\n6     1\n7     1\n8     1\n9     0\n10    0\n11    0\n12    0\n13    0\n14    0\n15    0\n16    0\n17    0\nName: 好瓜, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xigua_1_target = xigua['好瓜'].replace({\"是\":1,\"否\":0})\n",
    "xigua_1_target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.CategoricalNB()\n",
    "model.fit(xigua_1, xigua_1_target)\n",
    "model.score(xigua_1, xigua_1_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.ComplementNB()\n",
    "model.fit(xigua_1, xigua_1_target)\n",
    "model.score(xigua_1, xigua_1_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.GaussianNB()\n",
    "model.fit(xigua_1, xigua_1_target)\n",
    "model.score(xigua_1, xigua_1_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\venv\\torch\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n        4.9800e+00],\n       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n        9.1400e+00],\n       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n        4.0300e+00],\n       ...,\n       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n        5.6400e+00],\n       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n        6.4800e+00],\n       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n        7.8800e+00]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "boston = sklearn.datasets.load_boston()\n",
    "boston.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_y = [1 if y >boston.target.mean() else 0 for y in boston.target]\n",
    "boston_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.841897233201581"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.CategoricalNB()\n",
    "model.fit(boston.data, boston_y)\n",
    "model.score(boston.data, boston_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.717391304347826"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.ComplementNB()\n",
    "model.fit(boston.data, boston_y)\n",
    "model.score(boston.data, boston_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7450592885375494"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = naive_bayes.GaussianNB()\n",
    "model.fit(boston.data, boston_y)\n",
    "model.score(boston.data, boston_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
